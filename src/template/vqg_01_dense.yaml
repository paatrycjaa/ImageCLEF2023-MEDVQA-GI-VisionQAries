model_config:
  encoder_image_name: google/vit-base-patch16-224-in21k
  encoder_text_name: bert-base-uncased
  model_dropout: 0.5
  model_intermediate_dim: 512
  model_intermediate_dim_dense: 512
  test_data_size: 0.2
  type: VQG
training_config:
  seed: 12345
  evaluation_strategy: steps
  eval_steps: 1000
  logging_strategy: steps
  logging_steps: 1000
  save_strategy: steps
  save_steps: 1000
  save_total_limit: 3  # Since models are large, save only the last 3 checkpoints at any given time while training
  metric_for_best_model: acc
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  remove_unused_columns: False
  num_train_epochs: 10
  fp16: True
  dataloader_num_workers: 2
  load_best_model_at_end: True